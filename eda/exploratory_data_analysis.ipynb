{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "dataset1_path = \"../data/20240723/window1/dataset1.xlsx\"\n",
    "dataset2_path = \"../data/20240723/window1/dataset2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ORDER_ID ORDER_TIME  (PST)  CITY_DISTRICT_ID  RPTG_AMT CURRENCY_CD  \\\n",
      "0  G0000001198             50127                 1   1680.53         RMB   \n",
      "1  G0000001469             50127                 2   8760.18         RMB   \n",
      "2  G0000000001             50128                 3   7875.22         RMB   \n",
      "3  G0000001999             50132                 4  10353.10         RMB   \n",
      "4  G0000000002             50132                 5  11946.02         RMB   \n",
      "\n",
      "   ORDER_QTY  \n",
      "0        1.0  \n",
      "1        1.0  \n",
      "2        1.0  \n",
      "3        1.0  \n",
      "4        1.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159750 entries, 0 to 159749\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   ORDER_ID           159750 non-null  object \n",
      " 1   ORDER_TIME  (PST)  159750 non-null  object \n",
      " 2   CITY_DISTRICT_ID   159750 non-null  int64  \n",
      " 3   RPTG_AMT           159750 non-null  float64\n",
      " 4   CURRENCY_CD        159750 non-null  object \n",
      " 5   ORDER_QTY          159712 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file from the \"DATA\" sheet\n",
    "df_excel = pd.read_excel(dataset1_path, sheet_name='DATA')\n",
    "\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "print(df_excel.head())\n",
    "df_excel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_ID</th>\n",
       "      <th>ORDER_TIME  (PST)</th>\n",
       "      <th>CITY_DISTRICT_ID</th>\n",
       "      <th>RPTG_AMT</th>\n",
       "      <th>CURRENCY_CD</th>\n",
       "      <th>ORDER_QTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ORDER_ID, ORDER_TIME  (PST), CITY_DISTRICT_ID, RPTG_AMT, CURRENCY_CD, ORDER_QTY]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for unique ORDER_IDs\n",
    "duplicate_order_ids = df_excel[df_excel.duplicated('ORDER_ID', keep=False)]\n",
    "\n",
    "# Print the rows with conflicting ORDER_IDs\n",
    "duplicate_order_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ORDER_ID  ORDER_TIME_PST SHIP_TO_DISTRICT_NAME SHIP_TO_CITY_CD  \\\n",
      "0  G0000159216          110153                   河东区              天津   \n",
      "1  G0000159982          110153                   集美区              厦门   \n",
      "2  G0000163349          110153                   茂南区              茂名   \n",
      "3  G0000164476          110153                   槐荫区              济南   \n",
      "4  G0000166038          110153                   海城区              北海   \n",
      "\n",
      "   RPTG_AMT CURRENCY_CD  ORDER_QTY  \n",
      "0   7875.22         RMB          1  \n",
      "1  17520.35         RMB          2  \n",
      "2  10353.10         RMB          1  \n",
      "3   8760.18         RMB          1  \n",
      "4   7078.76         RMB          1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40236 entries, 0 to 40235\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   ORDER_ID               40236 non-null  object \n",
      " 1   ORDER_TIME_PST         40236 non-null  int64  \n",
      " 2   SHIP_TO_DISTRICT_NAME  40236 non-null  object \n",
      " 3   SHIP_TO_CITY_CD        40236 non-null  object \n",
      " 4   RPTG_AMT               40236 non-null  float64\n",
      " 5   CURRENCY_CD            40236 non-null  object \n",
      " 6   ORDER_QTY              40236 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read JSON file as DataFrame\n",
    "df_json = pd.read_json(dataset2_path)\n",
    "\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "print(df_json.head())\n",
    "df_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_ID</th>\n",
       "      <th>ORDER_TIME_PST</th>\n",
       "      <th>SHIP_TO_DISTRICT_NAME</th>\n",
       "      <th>SHIP_TO_CITY_CD</th>\n",
       "      <th>RPTG_AMT</th>\n",
       "      <th>CURRENCY_CD</th>\n",
       "      <th>ORDER_QTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ORDER_ID, ORDER_TIME_PST, SHIP_TO_DISTRICT_NAME, SHIP_TO_CITY_CD, RPTG_AMT, CURRENCY_CD, ORDER_QTY]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for unique ORDER_IDs\n",
    "duplicate_order_ids = df_json[df_json.duplicated('ORDER_ID', keep=False)]\n",
    "uniq_cnt_order_id_json = df_json[\"ORDER_ID\"].unique().shape[0]\n",
    "# Print the rows with conflicting ORDER_IDs\n",
    "duplicate_order_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique count of order id in json df:40236\n",
      "Unique count of order id in json df:159750\n"
     ]
    }
   ],
   "source": [
    "uniq_cnt_order_id_json = df_json[\"ORDER_ID\"].unique().shape[0]\n",
    "print(f\"Unique count of order id in json df:{uniq_cnt_order_id_json}\")\n",
    "uniq_cnt_order_id_excel = df_excel[\"ORDER_ID\"].unique().shape[0]\n",
    "print(f\"Unique count of order id in json df:{uniq_cnt_order_id_excel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_ID</th>\n",
       "      <th>ORDER_TIME  (PST)</th>\n",
       "      <th>CITY_DISTRICT_ID</th>\n",
       "      <th>RPTG_AMT_x</th>\n",
       "      <th>CURRENCY_CD_x</th>\n",
       "      <th>ORDER_QTY_x</th>\n",
       "      <th>ORDER_TIME_PST</th>\n",
       "      <th>SHIP_TO_DISTRICT_NAME</th>\n",
       "      <th>SHIP_TO_CITY_CD</th>\n",
       "      <th>RPTG_AMT_y</th>\n",
       "      <th>CURRENCY_CD_y</th>\n",
       "      <th>ORDER_QTY_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ORDER_ID, ORDER_TIME  (PST), CITY_DISTRICT_ID, RPTG_AMT_x, CURRENCY_CD_x, ORDER_QTY_x, ORDER_TIME_PST, SHIP_TO_DISTRICT_NAME, SHIP_TO_CITY_CD, RPTG_AMT_y, CURRENCY_CD_y, ORDER_QTY_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform an inner join on ORDER_ID\n",
    "df_joined = pd.merge(df_excel, df_json, on='ORDER_ID', how='inner')\n",
    "df_joined\n",
    "\n",
    "# Dataset 1 and 2 cannot be joined, they are likely the same datasets just in different source formats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of non-integer ORDER_QTY in df_json: 0\n",
      "Count of non-integer ORDER_QTY in df_excel: 38\n"
     ]
    }
   ],
   "source": [
    "# Define a function to check if ORDER_QTY fullfills constraints, for INT types\n",
    "def is_not_integer(value):\n",
    "    try:\n",
    "        int_value = int(value)\n",
    "        if int_value > 0:\n",
    "            return int_value != value\n",
    "    except (ValueError, TypeError):\n",
    "        return True\n",
    "\n",
    "# Apply the function to the ORDER_QTY column to filter non-integer values\n",
    "non_integer_count = df_json['ORDER_QTY'].apply(is_not_integer).sum()\n",
    "non_integer_count_xls = df_excel['ORDER_QTY'].apply(is_not_integer).sum()\n",
    "\n",
    "# Print the count of non-integer ORDER_QTY\n",
    "print(f\"Count of non-integer ORDER_QTY in df_json: {non_integer_count}\")\n",
    "print(f\"Count of non-integer ORDER_QTY in df_excel: {non_integer_count_xls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of CURRENCY_CD in df_excel:\n",
      "['RMB' 'USD']\n",
      "\n",
      "Unique values of CURRENCY_CD in df_json:\n",
      "['RMB']\n",
      "\n",
      "Count of rows in df_excel where CURRENCY_CD is not 'RMB': 37\n",
      "Count of rows in df_json where CURRENCY_CD is not 'RMB': 0\n"
     ]
    }
   ],
   "source": [
    "# Define a function to check if CURRENCY_CD fullfills constraints, for ENUM types\n",
    "\n",
    "# Get unique values of CURRENCY_CD in df_excel\n",
    "unique_currency_cd_excel = df_excel['CURRENCY_CD'].unique()\n",
    "print(\"Unique values of CURRENCY_CD in df_excel:\")\n",
    "print(unique_currency_cd_excel)\n",
    "\n",
    "# Get unique values of CURRENCY_CD in df_json\n",
    "unique_currency_cd_json = df_json['CURRENCY_CD'].unique()\n",
    "print(\"\\nUnique values of CURRENCY_CD in df_json:\")\n",
    "print(unique_currency_cd_json)\n",
    "\n",
    "# Count rows in df_excel where CURRENCY_CD is not 'RMB'\n",
    "count_not_rmb_excel = df_excel[df_excel['CURRENCY_CD'] != 'RMB'].shape[0]\n",
    "print(f\"\\nCount of rows in df_excel where CURRENCY_CD is not 'RMB': {count_not_rmb_excel}\")\n",
    "\n",
    "# Count rows in df_json where CURRENCY_CD is not 'RMB'\n",
    "count_not_rmb_json = df_json[df_json['CURRENCY_CD'] != 'RMB'].shape[0]\n",
    "print(f\"Count of rows in df_json where CURRENCY_CD is not 'RMB': {count_not_rmb_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows in df_excel where RPTG_AMT is not a float with 2 decimal places: 0\n",
      "Count of rows in df_json where RPTG_AMT is not a float with 2 decimal places: 0\n"
     ]
    }
   ],
   "source": [
    "# Type checks for dollar amounts using floats with 2 decimals. For RPTG_AMT\n",
    "\n",
    "# Function to check if values are floats with exactly 2 decimal places\n",
    "def check_two_decimals(df, column):\n",
    "    # Check if the values are numeric\n",
    "    is_numeric = pd.to_numeric(df[column], errors='coerce').notnull()\n",
    "    \n",
    "    # Check if the values have exactly 2 decimal places\n",
    "    decimal_check = df[is_numeric][column].apply(lambda x: round(x, 2) == x)\n",
    "    \n",
    "    # Check if the values are greater than 0\n",
    "    greater_than_zero = df[decimal_check][column].apply(lambda x: x > 0)\n",
    "    \n",
    "    # Combine both checks\n",
    "    valid_check = is_numeric & decimal_check & greater_than_zero\n",
    "    \n",
    "    # Count invalid values\n",
    "    invalid_count = (~valid_check).sum()\n",
    "    \n",
    "    return invalid_count, valid_check\n",
    "\n",
    "# Check RPTG_AMT in df_excel\n",
    "invalid_count_excel, valid_check_excel = check_two_decimals(df_excel, 'RPTG_AMT')\n",
    "print(f\"Count of rows in df_excel where RPTG_AMT is not a float with 2 decimal places: {invalid_count_excel}\")\n",
    "\n",
    "# Check RPTG_AMT in df_json\n",
    "invalid_count_json, valid_check_json = check_two_decimals(df_json, 'RPTG_AMT')\n",
    "print(f\"Count of rows in df_json where RPTG_AMT is not a float with 2 decimal places: {invalid_count_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CITY_DISTRICT_ID SHIP_TO_CITY_CD SHIP_TO_DISTRICT_NAME\n",
      "0                 1              厦门                   集美区\n",
      "1                 2              宣城                   宣州区\n",
      "2                 3              沈阳                   和平区\n",
      "3                 4              合肥                   瑶海区\n",
      "4                 5              扬州                   广陵区\n",
      "\n",
      "Unique values of SHIP_TO_CITY_CD in df_city_district_map:\n",
      "['厦门' '宣城' '沈阳' '合肥' '扬州' '吉安' '昆明' '上海' '佛山' '北京' '漳州' '成都' '重庆' '蚌埠'\n",
      " '广州' '镇江' '钦州' '唐山' '营口' '苏州' '海口' '湛江' '徐州' '九江' '平顶山' '铜仁' '长沙' '常州'\n",
      " '眉山' '温州' '济南' '哈尔滨' '贵阳' '西安' '衢州' '贺州' '东营' '玉林' '秦皇岛' '武汉' '长春' '无锡'\n",
      " '杭州' '连云港' '菏泽' '松原' '金华' '大同' '南通' '石家庄' '襄阳' '新乡' '晋中' '郑州' '洛阳' '丹东'\n",
      " '台州' '青岛' '曲靖' '红河哈尼族彝族自治州' '深圳' '淮北' '嘉兴' '乌鲁木齐' '天津' '双鸭山' '南京' '惠州'\n",
      " '佳木斯' '泸州' '阜阳' '保定' '泉州' '南充' '泰州' '汕头' '锦州' '淄博' '南昌' '廊坊' '鹤岗' '咸宁'\n",
      " '宁波' '凉山彝族自治州' '福州' '吉林' '宜昌' '赣州' '池州' '绵阳' '济宁' '亳州' '西宁' '葫芦岛' '文昌'\n",
      " '兴安盟' '东莞' '齐齐哈尔' '黄冈' '荆州' '抚州' '揭阳' '淮南' '芜湖' '黄石' '枣庄' '淮安' '张家口' '临沂'\n",
      " '绥化' '南宁' '盐城' '威海' '安阳' '景德镇' '安庆' '韶关' '宿迁' '湖州' '达州' '莆田' '江门' '呼和浩特'\n",
      " '潍坊' '衡阳' '中山' '鞍山' '孝感' '太原' '银川' '马鞍山' '牡丹江' '烟台' '延边朝鲜族自治州' '绍兴' '黄山'\n",
      " '河源' '萍乡' '荆门' '陇南' '伊春' '玉溪' '茂名' '梅州' '衡水' '临汾' '汉中' '宝鸡' '柳州'\n",
      " '黔西南布依族苗族自治州' '仙桃' '桂林' '十堰' '内江' '大理白族自治州' '焦作' '上饶' '长治' '百色' '宁德' '泰安'\n",
      " '延安' '包头' '邯郸' '六安' '大连' '盘锦' '株洲' '忻州' '南平' '德州' '榆林' '西双版纳傣族自治州' '辽阳'\n",
      " '宜宾' '渭南' '大庆' '阿勒泰地区' '潮州' '丽江' '遵义' '大兴安岭地区' '甘孜藏族自治州' '巴彦淖尔' '晋城' '信阳'\n",
      " '三门峡' '万宁' '阿坝藏族羌族自治州' '陵水黎族自治县' '毕节' '随州' '兰州' '阜新' '铜陵' '黑河' '怀化' '日照'\n",
      " '梧州' '保山' '攀枝花' '潜江' '承德' '资阳' '临夏回族自治州' '永州' '沧州' '龙岩' '抚顺' '南阳' '珠海'\n",
      " '雅安' '白山' '聊城' '宿州' '宜春' '咸阳' '肇庆' '商丘' '三亚' '阳泉' '铁岭' '铜川' '许昌' '三明'\n",
      " '通辽' '崇左' '广元' '鸡西' '黔南布依族苗族自治州' '巴中' '清远' '驻马店' '德宏傣族景颇族自治州' '常德' '开封'\n",
      " '滁州' '黔东南苗族侗族自治州' '呼伦贝尔' '漯河' '石嘴山' '通化' '汕尾' '新余' '拉萨' '鹰潭' '周口' '贵港'\n",
      " '乌海' '益阳' '北海' '楚雄彝族自治州' '哈密市' '吕梁' '丽水' '舟山' '湘潭' '恩施土家族苗族自治州' '邵阳' '鄂州'\n",
      " '安顺' '遂宁' '阳江' '鹤壁' '朝阳' '邢台' '濮阳' '四平' '定西' '自贡' '伊犁哈萨克自治州' '昭通' '鄂尔多斯'\n",
      " '朔州' '昆玉' '巴音郭楞蒙古自治州' '林芝' '天门' '辽源' '乐山' '娄底' '运城' '白城' '琼海' '酒泉' '郴州'\n",
      " '滨州' '迪庆藏族自治州' '岳阳' '河池' '云浮' '广安' '武威' '德阳' '七台河' '海南藏族自治州' '金昌' '喀什地区'\n",
      " '山南市' '临沧' '六盘水' '克拉玛依' '商洛' '固原' '昌吉回族自治州' '阿克苏地区' '博尔塔拉蒙古自治州' '庆阳' '平凉'\n",
      " '锡林郭勒盟' '普洱' '乌兰察布' '黄南藏族自治州' '石河子' '乐东黎族自治县' '吴忠' '日喀则' '湘西土家族苗族自治州'\n",
      " '塔城地区' '海西蒙古族藏族自治州' '本溪' '和田地区' '文山壮族苗族自治州' '来宾' '克孜勒苏柯尔克孜自治州' '中卫' '临高县'\n",
      " '赤峰' '嘉峪关' '阿拉善盟' '济源' '澄迈县' '防城港' '安康' '定安县' '那曲市' '天水' '海东' '张家界' '白银'\n",
      " '儋州' '玉树藏族自治州' '吐鲁番' '海北藏族自治州' '果洛藏族自治州' '昌都' '保亭黎族苗族自治县' '神农架林区' '五指山'\n",
      " '张掖' '琼中黎族苗族自治县' '屯昌县' '东方' '怒江傈僳族自治州' '图木舒克' '甘南藏族自治州' '北屯' '阿拉尔'\n",
      " '昌江黎族自治县' '阿里地区' '五家渠' '白沙黎族自治县']\n",
      "\n",
      "Count of Unique values of SHIP_TO_CITY_CD in df_city_district_map:\n",
      "362\n",
      "\n",
      "Unique values of SHIP_TO_DISTRICT_NAME in df_city_district_map:\n",
      "['集美区' '宣州区' '和平区' ... '全南县' '凤庆县' '曲水县']\n",
      "\n",
      "Count of Unique values of SHIP_TO_DISTRICT_NAME in df_city_district_map:\n",
      "2545\n"
     ]
    }
   ],
   "source": [
    "# Type checks for CITY_DISTRICT_ID of type ENUM, check if values are within known mapping tables \n",
    "\n",
    "# Load the Excel file from the \"CITY_DISTRICT_MAP\" sheet\n",
    "df_city_district_map = pd.read_excel(dataset1_path, sheet_name='CITY_DISTRICT_MAP')\n",
    "\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "print(df_city_district_map.head())\n",
    "\n",
    "# Print all unique values of SHIP_TO_CITY_CD\n",
    "unique_city_cd = df_city_district_map['SHIP_TO_CITY_CD'].unique()\n",
    "unique_city_cd_cnt = unique_city_cd.shape[0]\n",
    "print(\"\\nUnique values of SHIP_TO_CITY_CD in df_city_district_map:\")\n",
    "print(unique_city_cd)\n",
    "print(\"\\nCount of Unique values of SHIP_TO_CITY_CD in df_city_district_map:\")\n",
    "print(unique_city_cd_cnt)\n",
    "\n",
    "# Print all unique values of SHIP_TO_DISTRICT_NAME\n",
    "unique_district_name = df_city_district_map['SHIP_TO_DISTRICT_NAME'].unique()\n",
    "unique_district_name_cnt = unique_district_name.shape[0]\n",
    "print(\"\\nUnique values of SHIP_TO_DISTRICT_NAME in df_city_district_map:\")\n",
    "print(unique_district_name)\n",
    "print(\"\\nCount of Unique values of SHIP_TO_DISTRICT_NAME in df_city_district_map:\")\n",
    "print(unique_district_name_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ORDER_ID ORDER_TIME  (PST)  CITY_DISTRICT_ID  RPTG_AMT CURRENCY_CD  \\\n",
      "130260  G0000135715            102931            999999   8760.18         RMB   \n",
      "130261  G0000133962            102931            999999   7078.76         RMB   \n",
      "130262  G0000136128            102931            999999   7963.72         RMB   \n",
      "130263  G0000127580            102931            999999   7875.22         RMB   \n",
      "130264  G0000131236            102931            999999   7078.76         RMB   \n",
      "130265  G0000132568            102931            999999   7963.72         RMB   \n",
      "130266  G0000134560            102931            999999   7875.22         RMB   \n",
      "130267  G0000133862            102931            999999  10353.10         RMB   \n",
      "130268  G0000133863            102931            999999   1325.66         RMB   \n",
      "130269  G0000135936            102932            999999   7078.76         RMB   \n",
      "130270  G0000129971            102932            999999   8760.18         RMB   \n",
      "130271  G0000135324            102932            999999   8760.18         RMB   \n",
      "130272  G0000135114            102932            999999   8760.18         RMB   \n",
      "130273  G0000134357            102932            999999   7875.22         RMB   \n",
      "130274  G0000130587            102932            999999  20706.19         RMB   \n",
      "130275  G0000136845            102933            999999   8760.18         RMB   \n",
      "130276  G0000134441            102933            999999  10353.10         RMB   \n",
      "130277  G0000136577            102933            999999   8760.18         RMB   \n",
      "130278  G0000134160            102933            999999   8760.18         RMB   \n",
      "130279  G0000136211            102933            999999   1680.53         RMB   \n",
      "130280  G0000132931            102933            999999   8760.18         RMB   \n",
      "130281  G0000135545            102933            999999   7963.72         RMB   \n",
      "130282  G0000135575            102933            999999  10353.10         RMB   \n",
      "130283  G0000110723            102934            999999  17520.35         RMB   \n",
      "130284  G0000134931            102934            999999   7875.22         RMB   \n",
      "130285  G0000135632            102934            999999  10353.10         RMB   \n",
      "130286  G0000133388            102934            999999   7875.22         RMB   \n",
      "130287  G0000136365            102934            999999   7875.22         RMB   \n",
      "130288  G0000129589            102934            999999  11061.06         RMB   \n",
      "130289  G0000135268            102934            999999   8760.18         RMB   \n",
      "130290  G0000135415            102934            999999   7875.22         RMB   \n",
      "130291  G0000129588            102935            999999  11946.02         RMB   \n",
      "130292  G0000135226            102935            999999   8760.18         RMB   \n",
      "130293  G0000135020            102935            999999   8760.18         RMB   \n",
      "130294  G0000135716            102935            999999   8760.18         RMB   \n",
      "130295  G0000134561            102935            999999  10353.10         RMB   \n",
      "130296  G0000119284            102935            999999   8760.18         RMB   \n",
      "\n",
      "        ORDER_QTY  \n",
      "130260        1.0  \n",
      "130261        1.0  \n",
      "130262        1.0  \n",
      "130263        1.0  \n",
      "130264        1.0  \n",
      "130265        1.0  \n",
      "130266        1.0  \n",
      "130267        1.0  \n",
      "130268        1.0  \n",
      "130269        1.0  \n",
      "130270        1.0  \n",
      "130271        1.0  \n",
      "130272        1.0  \n",
      "130273        1.0  \n",
      "130274        2.0  \n",
      "130275        1.0  \n",
      "130276        1.0  \n",
      "130277        1.0  \n",
      "130278        1.0  \n",
      "130279        1.0  \n",
      "130280        1.0  \n",
      "130281        1.0  \n",
      "130282        1.0  \n",
      "130283        2.0  \n",
      "130284        1.0  \n",
      "130285        1.0  \n",
      "130286        1.0  \n",
      "130287        1.0  \n",
      "130288        1.0  \n",
      "130289        1.0  \n",
      "130290        1.0  \n",
      "130291        1.0  \n",
      "130292        1.0  \n",
      "130293        1.0  \n",
      "130294        1.0  \n",
      "130295        1.0  \n",
      "130296        1.0  \n",
      "Count of invalid city district_ids in dataset1: 37\n"
     ]
    }
   ],
   "source": [
    "# Find rows where CITY_DISTRICT_ID in df_excel is not present in df_city_district_map\n",
    "invalid_city_district_ids = df_excel[~df_excel['CITY_DISTRICT_ID'].isin(df_city_district_map['CITY_DISTRICT_ID'])]\n",
    "invalid_city_district_ids_cnt  = invalid_city_district_ids.shape[0]\n",
    "\n",
    "# Display the rows with invalid CITY_DISTRICT_ID\n",
    "print(invalid_city_district_ids)\n",
    "print(f\"Count of invalid city district_ids in dataset1: {invalid_city_district_ids_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'山南', '莱芜'} {'墨竹工卡县', '右玉县', '合阳县', '国营山荣农场', '遂平县', '吉木乃县', '东凤镇', '横州市', '阿克塞哈萨克族自治县', '关岭布依族苗族自治县', '东区街道', '凌云县', '札达县', '射洪县', '泸溪县', '蓬溪县', '伊春区', '特克斯县', '武功县', '乃东区', '喜德县', '贡嘎县', '凤岗镇', '富民县', '志丹县', '罗甸县', '木垒哈萨克自治县', '灵台县', '洪江市', '任泽区', '小榄镇', '邢台县', '大英县', '丹巴县', '德保县', '祁阳市', '河南蒙古族自治县', '巴马瑶族自治县', '常平镇', '平塘县', '呼中区', '乌拉特后旗', '其它区', '永年县', '米林县', '林甸县', '交口县', '甘泉县', '太谷县', '库车县', '松潘县', '白河县', '丰镇市', '库车市', '连山壮族瑶族自治县', '繁昌区', '尼勒克县', '茶山镇', '茌平县', '柏乡县', '石拐区', '松山湖管委会', '石渠县', '寮步镇', '洞口县', '兴仁县', '莞城街道', '两当县', '塘厦镇', '泰宁县', '平乐县', '漾濞彝族自治县', '延川县', '类乌齐县', '天祝藏族自治县', '涞源县', '洛川县', '黔西市', '西吉县', '碌曲县', '沅陵县', '东兰县', '峡江县', '额尔古纳市', '永胜县', '沧源佤族自治县'}\n",
      "2 86\n"
     ]
    }
   ],
   "source": [
    "# Find rows where SHIP_TO_CITY_CD and SHIP_TO_DISTRICT_NAME in df_json is not present in df_city_district_map\n",
    "\n",
    "# Extract CITY_CD and DISTRICT_NAME from df_json\n",
    "city_cd_json = df_json['SHIP_TO_CITY_CD'].unique()\n",
    "district_name_json = df_json[\"SHIP_TO_DISTRICT_NAME\"].unique()\n",
    "\n",
    "# Extract CITY_CD and DISTRICT_NAME from the mapping table\n",
    "city_cd_map = df_city_district_map['SHIP_TO_CITY_CD'].unique()\n",
    "district_name_map = df_city_district_map['SHIP_TO_DISTRICT_NAME'].unique()\n",
    "\n",
    "# Find CITY_CD and DISTRICT_NAME from JSON that are not in the mapping table\n",
    "missing_city_cd = set(city_cd_json) - set(city_cd_map)\n",
    "missing_district_name = set(district_name_json) -  set(district_name_map)\n",
    "\n",
    "print(missing_city_cd, missing_district_name)\n",
    "print(len(missing_city_cd), len(missing_district_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_ID</th>\n",
       "      <th>ORDER_TIME_PST</th>\n",
       "      <th>SHIP_TO_DISTRICT_NAME</th>\n",
       "      <th>SHIP_TO_CITY_CD</th>\n",
       "      <th>RPTG_AMT</th>\n",
       "      <th>CURRENCY_CD</th>\n",
       "      <th>ORDER_QTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>G0000166194</td>\n",
       "      <td>110159</td>\n",
       "      <td>松潘县</td>\n",
       "      <td>阿坝藏族羌族自治州</td>\n",
       "      <td>7875.22</td>\n",
       "      <td>RMB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>G0000167260</td>\n",
       "      <td>110234</td>\n",
       "      <td>伊春区</td>\n",
       "      <td>伊春</td>\n",
       "      <td>8760.18</td>\n",
       "      <td>RMB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>G0000162868</td>\n",
       "      <td>110247</td>\n",
       "      <td>延川县</td>\n",
       "      <td>延安</td>\n",
       "      <td>8760.18</td>\n",
       "      <td>RMB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>G0000163360</td>\n",
       "      <td>110252</td>\n",
       "      <td>国营山荣农场</td>\n",
       "      <td>乐东黎族自治县</td>\n",
       "      <td>7875.22</td>\n",
       "      <td>RMB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>G0000145199</td>\n",
       "      <td>110310</td>\n",
       "      <td>凌云县</td>\n",
       "      <td>百色</td>\n",
       "      <td>7875.22</td>\n",
       "      <td>RMB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39113</th>\n",
       "      <td>G0000204735</td>\n",
       "      <td>114735</td>\n",
       "      <td>祁阳市</td>\n",
       "      <td>永州</td>\n",
       "      <td>8760.18</td>\n",
       "      <td>RMB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39523</th>\n",
       "      <td>G0000205879</td>\n",
       "      <td>114748</td>\n",
       "      <td>泸溪县</td>\n",
       "      <td>湘西土家族苗族自治州</td>\n",
       "      <td>8760.18</td>\n",
       "      <td>RMB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39598</th>\n",
       "      <td>G0000190816</td>\n",
       "      <td>114751</td>\n",
       "      <td>钢城区</td>\n",
       "      <td>莱芜</td>\n",
       "      <td>6105.31</td>\n",
       "      <td>RMB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39886</th>\n",
       "      <td>G0000199129</td>\n",
       "      <td>114800</td>\n",
       "      <td>涞源县</td>\n",
       "      <td>保定</td>\n",
       "      <td>10353.10</td>\n",
       "      <td>RMB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40088</th>\n",
       "      <td>G0000177929</td>\n",
       "      <td>114807</td>\n",
       "      <td>巴马瑶族自治县</td>\n",
       "      <td>河池</td>\n",
       "      <td>8760.18</td>\n",
       "      <td>RMB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ORDER_ID  ORDER_TIME_PST SHIP_TO_DISTRICT_NAME SHIP_TO_CITY_CD  \\\n",
       "88     G0000166194          110159                   松潘县       阿坝藏族羌族自治州   \n",
       "557    G0000167260          110234                   伊春区              伊春   \n",
       "719    G0000162868          110247                   延川县              延安   \n",
       "789    G0000163360          110252                国营山荣农场         乐东黎族自治县   \n",
       "1014   G0000145199          110310                   凌云县              百色   \n",
       "...            ...             ...                   ...             ...   \n",
       "39113  G0000204735          114735                   祁阳市              永州   \n",
       "39523  G0000205879          114748                   泸溪县      湘西土家族苗族自治州   \n",
       "39598  G0000190816          114751                   钢城区              莱芜   \n",
       "39886  G0000199129          114800                   涞源县              保定   \n",
       "40088  G0000177929          114807               巴马瑶族自治县              河池   \n",
       "\n",
       "       RPTG_AMT CURRENCY_CD  ORDER_QTY  \n",
       "88      7875.22         RMB          1  \n",
       "557     8760.18         RMB          1  \n",
       "719     8760.18         RMB          1  \n",
       "789     7875.22         RMB          1  \n",
       "1014    7875.22         RMB          1  \n",
       "...         ...         ...        ...  \n",
       "39113   8760.18         RMB          1  \n",
       "39523   8760.18         RMB          1  \n",
       "39598   6105.31         RMB          1  \n",
       "39886  10353.10         RMB          1  \n",
       "40088   8760.18         RMB          1  \n",
       "\n",
       "[122 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter df_json rows which cannot be joined to mapping table\n",
    "unjoinable_rows = df_json[~df_json['SHIP_TO_CITY_CD'].isin(set(city_cd_map)) | ~df_json['SHIP_TO_DISTRICT_NAME'].isin(set(district_name_map))]\n",
    "\n",
    "unjoinable_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 3, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the reason why the rows are unjoinable\n",
    "\n",
    "# Find rows where DISTRICT is not in the mapping table\n",
    "unjoinable_due_to_district = unjoinable_rows[~unjoinable_rows['SHIP_TO_DISTRICT_NAME'].isin(set(district_name_map))]\n",
    "\n",
    "# Find rows where CITY is not in the mapping table\n",
    "unjoinable_due_to_city = unjoinable_rows[~unjoinable_rows['SHIP_TO_CITY_CD'].isin(set(city_cd_map))]\n",
    "\n",
    "# Find rows where both CITY and DISTRICT pair is not in the mapping table\n",
    "unjoinable_due_to_both = unjoinable_rows[\n",
    "    (~unjoinable_rows['SHIP_TO_DISTRICT_NAME'].isin(set(district_name_map))) &\n",
    "    (~unjoinable_rows['SHIP_TO_CITY_CD'].isin(set(city_cd_map)))\n",
    "]\n",
    "\n",
    "# Get counts for each category\n",
    "count_due_to_district = unjoinable_due_to_district.shape[0]\n",
    "count_due_to_city = unjoinable_due_to_city.shape[0]\n",
    "count_due_to_both = unjoinable_due_to_both.shape[0]\n",
    "\n",
    "count_due_to_district, count_due_to_city, count_due_to_both\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Feature - Wikipedia Scraping Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# URL of the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_cities_in_China\"\n",
    "\n",
    "# Use pandas to read the HTML tables from the page\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Iterate through tables to find the one with the list of cities\n",
    "for i, table in enumerate(tables):\n",
    "    if 'Province' in table.columns and 'City' in table.columns:\n",
    "        df_cities = table\n",
    "        break\n",
    "\n",
    "# Display the first few rows of the dataframe to verify\n",
    "print(df_cities.head())\n",
    "print(df_cities.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create a function to check if a value is a substring of any entry in a column\n",
    "    def is_substring(value, series):\n",
    "        return any(value in str(city) for city in series)\n",
    "\n",
    "# Remove duplicates from df_json[\"SHIP_TO_CITY_CD\"]\n",
    "df_json_unique = df_json.drop_duplicates(subset=['SHIP_TO_CITY_CD']).copy()\n",
    "\n",
    "# Apply the function to each unique city code in df_json_unique\n",
    "df_json_unique.loc[:, 'city_match'] = df_json_unique['SHIP_TO_CITY_CD'].apply(lambda x: is_substring(x, df_cities['Chinese']))\n",
    "\n",
    "# Filter rows where city_match is False\n",
    "df_json_no_match = df_json_unique[df_json_unique['city_match'] == False]\n",
    "# Remove duplicates from df_city_district_map[\"SHIP_TO_CITY_CD\"]\n",
    "df_city_district_map_unique = df_city_district_map.drop_duplicates(subset=['SHIP_TO_CITY_CD']).copy()\n",
    "\n",
    "# Apply the function to each unique city code in df_city_district_map_unique\n",
    "df_city_district_map_unique.loc[:, 'city_match'] = df_city_district_map_unique['SHIP_TO_CITY_CD'].apply(lambda x: is_substring(x, df_cities['Chinese']))\n",
    "\n",
    "# Count the number of rows where city_match is True\n",
    "count_matches = df_json_unique['city_match'].sum()\n",
    "count_matches_excel = df_city_district_map_unique['city_match'].sum()\n",
    "\n",
    "# Print the counts\n",
    "print(count_matches)\n",
    "print(df_json_unique[\"SHIP_TO_CITY_CD\"].unique().shape[0])\n",
    "\n",
    "print(count_matches_excel)\n",
    "print(df_city_district_map_unique[\"SHIP_TO_CITY_CD\"].unique().shape[0])\n",
    "print(df_json_no_match)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
